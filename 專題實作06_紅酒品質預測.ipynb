{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmJz/FFF3kF7Sj8AMznb0D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenjan1974/Prediction-of-quality-of-Wine/blob/main/%E5%B0%88%E9%A1%8C%E5%AF%A6%E4%BD%9C06_%E7%B4%85%E9%85%92%E5%93%81%E8%B3%AA%E9%A0%90%E6%B8%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6pp9g46BB7W",
        "outputId": "25298f16-407f-4869-e7a7-ac1168eab952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
            "fixed_acidity           float64\n",
            "volatile_acidity        float64\n",
            "citric_acid             float64\n",
            "residual_sugar          float64\n",
            "chlorides               float64\n",
            "free_sulfur_dioxide     float64\n",
            "total_sulfur_dioxide    float64\n",
            "density                 float64\n",
            "pH                      float64\n",
            "sulphates               float64\n",
            "alcohol                 float64\n",
            "quality                   int64\n",
            "dtype: object\n",
            "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
            "0            7.7             0.620         0.04             3.8      0.084   \n",
            "1            8.2             0.635         0.10             2.1      0.073   \n",
            "2            8.4             0.370         0.43             2.3      0.063   \n",
            "3            9.9             0.490         0.58             3.5      0.094   \n",
            "4            6.3             1.020         0.00             2.0      0.083   \n",
            "\n",
            "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
            "0                 25.0                  45.0  0.99780  3.34       0.53   \n",
            "1                 25.0                  60.0  0.99638  3.29       0.75   \n",
            "2                 12.0                  19.0  0.99550  3.17       0.81   \n",
            "3                  9.0                  43.0  1.00040  3.29       0.58   \n",
            "4                 17.0                  24.0  0.99437  3.59       0.55   \n",
            "\n",
            "   alcohol  quality  \n",
            "0      9.5        5  \n",
            "1     10.9        6  \n",
            "2     11.2        7  \n",
            "3      9.0        5  \n",
            "4     11.2        4  \n",
            "與 quality 相關係數前五：\n",
            " alcohol             0.480343\n",
            "volatile_acidity    0.395214\n",
            "sulphates           0.248835\n",
            "citric_acid         0.228057\n",
            "density             0.184252\n",
            "Name: quality, dtype: float64\n",
            "隨機森林前五重要特徵：\n",
            " alcohol                 0.146989\n",
            "sulphates               0.108748\n",
            "volatile_acidity        0.105418\n",
            "total_sulfur_dioxide    0.100380\n",
            "density                 0.091568\n",
            "dtype: float64\n",
            "StandardScaler 統計量：\n",
            "       fixed_acidity  volatile_acidity  residual_sugar\n",
            "min   -2.137008e+00     -2.238023e+00   -1.200903e+00\n",
            "max    4.370894e+00      5.741690e+00    9.599383e+00\n",
            "mean   3.862498e-16      1.333248e-16   -1.150253e-16\n",
            "std    1.000368e+00      1.000368e+00    1.000368e+00\n",
            "MinMaxScaler 統計量：\n",
            "       fixed_acidity  volatile_acidity  residual_sugar\n",
            "min        0.000000          0.000000        0.000000\n",
            "max        1.000000          1.000000        1.000000\n",
            "mean       0.328371          0.280464        0.111192\n",
            "std        0.153716          0.125364        0.092624\n",
            "Baseline CV 分數： [0.59633028 0.63761468 0.57142857 0.62672811 0.59447005]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.neighbors       import KNeighborsClassifier\n",
        "from sklearn.tree            import DecisionTreeClassifier\n",
        "from sklearn.svm             import SVC\n",
        "from xgboost                 import XGBClassifier\n",
        "\n",
        "# 1. 用逗號分隔讀檔（不用 sep=';'）\n",
        "df = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/aniruddhachoudhury/'\n",
        "    'Red-Wine-Quality/master/winequality-red.csv'\n",
        ")\n",
        "\n",
        "# 2. 清理欄名：去頭尾空白、空格換底線\n",
        "df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "\n",
        "# 3. 去重、去 NA，再打散重設索引\n",
        "df_train = (\n",
        "    df.drop_duplicates()\n",
        "      .dropna()\n",
        "      .sample(frac=1, random_state=42)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# 列出所有欄位名稱\n",
        "print(df_train.columns.tolist())\n",
        "\n",
        "# 查看每個欄位的 dtype\n",
        "print(df_train.dtypes)\n",
        "\n",
        "# 看前 5 筆\n",
        "print(df_train.head())\n",
        "\n",
        "# 4. 相關係數觀測\n",
        "corr = df_train.corr()['quality'].drop('quality')\n",
        "print(\"與 quality 相關係數前五：\\n\", corr.abs().sort_values(ascending=False).head(5))\n",
        "\n",
        "# 5. 隨機森林特徵重要性\n",
        "X = df_train.drop('quality', axis=1)\n",
        "y = df_train['quality']\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42).fit(X, y)\n",
        "importances = pd.Series(rfc.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(\"隨機森林前五重要特徵：\\n\", importances.head(5))\n",
        "\n",
        "# 6. 正規化比較\n",
        "features = ['fixed_acidity','volatile_acidity','residual_sugar']\n",
        "std = StandardScaler().fit_transform(df_train[features])\n",
        "df_std = pd.DataFrame(std, columns=features).describe().loc[['min','max','mean','std']]\n",
        "\n",
        "mm = MinMaxScaler().fit_transform(df_train[features])\n",
        "df_mm = pd.DataFrame(mm, columns=features).describe().loc[['min','max','mean','std']]\n",
        "\n",
        "print(\"StandardScaler 統計量：\\n\", df_std)\n",
        "print(\"MinMaxScaler 統計量：\\n\", df_mm)\n",
        "\n",
        "# 7. Baseline 跑 RFC\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "rfc_baseline = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "scores = cross_val_score(rfc_baseline, X_train, y_train, cv=5)\n",
        "print(\"Baseline CV 分數：\", scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBzTQEoidCey",
        "outputId": "018b8f8f-890c-46d5-b03a-2d2809a5b511"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.neighbors       import KNeighborsClassifier\n",
        "from sklearn.tree            import DecisionTreeClassifier\n",
        "from sklearn.svm             import SVC\n",
        "from xgboost                 import XGBClassifier\n",
        "\n",
        "df = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/aniruddhachoudhury/'\n",
        "    'Red-Wine-Quality/master/winequality-red.csv'\n",
        ")\n",
        "\n",
        "\n",
        "df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "\n",
        "\n",
        "df_train = (\n",
        "    df.drop_duplicates()\n",
        "      .dropna()\n",
        "      .sample(frac=1, random_state=42)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "\n",
        "X = df_train.drop('quality', axis=1)\n",
        "y = df_train['quality']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# # 1. scikit-learn 基本分類器比較\n",
        "# models = {\n",
        "#     'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "#     'KNN':                KNeighborsClassifier(),\n",
        "#     'DecisionTree':       DecisionTreeClassifier(class_weight='balanced'),\n",
        "#     'RandomForest':       RandomForestClassifier(n_estimators=200, class_weight='balanced'),\n",
        "#     'SVC':                SVC(class_weight='balanced')\n",
        "# }\n",
        "\n",
        "# results = []\n",
        "# for name, model in models.items():\n",
        "#     scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
        "#     results.append({\n",
        "#         'model': name,\n",
        "#         'mean_acc': scores.mean(),\n",
        "#         'std_acc':  scores.std()\n",
        "#     })\n",
        "\n",
        "# df_results = pd.DataFrame(results).sort_values('mean_acc', ascending=False)\n",
        "# print(\"—— scikit-learn 分類器比較 ——\")\n",
        "# print(df_results)\n",
        "\n",
        "\n",
        "# # 2. GridSearchCV 調參（以 RandomForest 為例）\n",
        "# param_grid = {\n",
        "#     'n_estimators': [100, 200, 300],\n",
        "#     'max_depth':    [None, 10, 20],\n",
        "#     'min_samples_split': [2, 5]\n",
        "# }\n",
        "# gs = GridSearchCV(\n",
        "#     RandomForestClassifier(class_weight='balanced', random_state=42),\n",
        "#     param_grid,\n",
        "#     cv=3,\n",
        "#     scoring='accuracy',\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "# gs.fit(X, y)\n",
        "# print(\"最佳參數：\", gs.best_params_)\n",
        "# print(\"最佳交叉驗證分數：\", gs.best_score_)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# 3a. XGBoost 分類\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "scores_xgb = cross_val_score(xgb, X, y_encoded, cv=5, scoring='accuracy')\n",
        "print(\"XGBoost Accuracy:\", scores_xgb.mean(), \"+/-\", scores_xgb.std())\n",
        "\n",
        "# 3b. TensorFlow Keras 簡易全連接網路\n",
        "\n",
        "# 轉成 one-hot（視多分類情況）\n",
        "y_cat = to_categorical(y - y.min())  # 如果 quality 最小是3，就 -3 再做 one-hot\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(y_cat.shape[1], activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1)\n",
        "print(\"Keras Test Accuracy:\", model.evaluate(X_test, y_test)[1])\n",
        "\n",
        "# 3c. PyTorch 簡易全連接網路（示意）\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 準備資料\n",
        "# 資料轉換\n",
        "X_t = torch.tensor(X.values, dtype=torch.float32)\n",
        "\n",
        "# 重新 LabelEncode y\n",
        "le_torch = LabelEncoder()\n",
        "y_t = torch.tensor(le_torch.fit_transform(y), dtype=torch.long)\n",
        "dataset = TensorDataset(X_t, y_t)\n",
        "loader  = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 模型\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, out_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "net = Net(X.shape[1], 64, len(y.unique()))\n",
        "opt = optim.Adam(net.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 訓練一個 epoch\n",
        "net.train()\n",
        "for xb, yb in loader:\n",
        "    opt.zero_grad()\n",
        "    preds = net(xb)\n",
        "    loss = loss_fn(preds, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "print(\"PyTorch 一輪訓練完成，loss=\", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix3aV3m-aqn8",
        "outputId": "b9ead01b-c6f8-4f72-f42d-41f9d12e76d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:36:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:36:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:36:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:36:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:36:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.5901372910787932 +/- 0.010885405968173882\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.3273 - loss: 6.0907 - val_accuracy: 0.4037 - val_loss: 1.3068\n",
            "Epoch 2/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4418 - loss: 1.3515 - val_accuracy: 0.4954 - val_loss: 1.2620\n",
            "Epoch 3/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5034 - loss: 1.1982 - val_accuracy: 0.4587 - val_loss: 1.2405\n",
            "Epoch 4/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5017 - loss: 1.1402 - val_accuracy: 0.4037 - val_loss: 1.2428\n",
            "Epoch 5/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5334 - loss: 1.1554 - val_accuracy: 0.4862 - val_loss: 1.2427\n",
            "Epoch 6/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5493 - loss: 1.1584 - val_accuracy: 0.4587 - val_loss: 1.2517\n",
            "Epoch 7/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5280 - loss: 1.1581 - val_accuracy: 0.4679 - val_loss: 1.2778\n",
            "Epoch 8/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5257 - loss: 1.1311 - val_accuracy: 0.4312 - val_loss: 1.2378\n",
            "Epoch 9/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5320 - loss: 1.1199 - val_accuracy: 0.4771 - val_loss: 1.2617\n",
            "Epoch 10/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5259 - loss: 1.0978 - val_accuracy: 0.4679 - val_loss: 1.2551\n",
            "Epoch 11/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5353 - loss: 1.1361 - val_accuracy: 0.4587 - val_loss: 1.2485\n",
            "Epoch 12/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5196 - loss: 1.1522 - val_accuracy: 0.4495 - val_loss: 1.2432\n",
            "Epoch 13/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5286 - loss: 1.1138 - val_accuracy: 0.3853 - val_loss: 1.2755\n",
            "Epoch 14/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5194 - loss: 1.1094 - val_accuracy: 0.4495 - val_loss: 1.2568\n",
            "Epoch 15/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5416 - loss: 1.0785 - val_accuracy: 0.4495 - val_loss: 1.2565\n",
            "Epoch 16/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5148 - loss: 1.1235 - val_accuracy: 0.4404 - val_loss: 1.2605\n",
            "Epoch 17/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5363 - loss: 1.0964 - val_accuracy: 0.4220 - val_loss: 1.2966\n",
            "Epoch 18/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5412 - loss: 1.0591 - val_accuracy: 0.4312 - val_loss: 1.2416\n",
            "Epoch 19/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5476 - loss: 1.1059 - val_accuracy: 0.4495 - val_loss: 1.2402\n",
            "Epoch 20/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5125 - loss: 1.1206 - val_accuracy: 0.4771 - val_loss: 1.2383\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5053 - loss: 1.1270 \n",
            "Keras Test Accuracy: 0.5\n",
            "PyTorch 一輪訓練完成，loss= 1.3021855354309082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **關係大的特徵：定義與觀察方法**\n",
        "   我們可以用「與品質分數的絕對 Pearson 相關係數」或「模型（如隨機森林）的特徵重要性」來衡量「關係大」。\n",
        "\n",
        "   ```python\n",
        "   # 計算相關係數\n",
        "   corr = df_train.corr()['quality'].drop('quality')\n",
        "   corr_abs = corr.abs().sort_values(ascending=False)\n",
        "   print(\"最相關的幾個特徵：\")\n",
        "   print(corr_abs.head(5))\n",
        "\n",
        "   # 隨機森林特徵重要性\n",
        "   from sklearn.ensemble import RandomForestClassifier\n",
        "   X = df_train.drop('quality', axis=1)\n",
        "   y = df_train['quality']\n",
        "   rfc = RandomForestClassifier(n_estimators=100, random_state=42).fit(X, y)\n",
        "   importances = pd.Series(rfc.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "   print(\"最重要的幾個特徵：\")\n",
        "   print(importances.head(5))\n",
        "   ```\n",
        "\n",
        "   * **常見結果**：`alcohol`、`sulphates`、`volatile_acidity`、`citric_acid`、`density` 通常名列前茅。\n",
        "\n",
        "2. **可排除的多餘欄位**\n",
        "\n",
        "   * 如果某特徵與品質相關性極低（絕對相關係數 < 0.05）且在模型中重要性也接近 0，就可考慮剔除。\n",
        "   * 例如 `chlorides`、`citric_acid`（視實際排序而定）可能可以移除，以減少雜訊與計算成本。\n",
        "\n",
        "3. **比較不同正規化方法**\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "   features = ['fixed_acidity','volatile_acidity','residual_sugar']\n",
        "   # Standard\n",
        "   std = StandardScaler().fit_transform(df_train[features])\n",
        "   df_std = pd.DataFrame(std, columns=features).describe().loc[['min','max','mean','std']]\n",
        "   # Min-Max\n",
        "   mm = MinMaxScaler().fit_transform(df_train[features])\n",
        "   df_mm = pd.DataFrame(mm, columns=features).describe().loc[['min','max','mean','std']]\n",
        "\n",
        "   print(\"StandardScaler 統計量：\\n\", df_std)\n",
        "   print(\"MinMaxScaler 統計量：\\n\", df_mm)\n",
        "   ```\n",
        "\n",
        "   * **Standardizer** 令資料平均為 0、標準差為 1；適合對「分佈近常態」的特徵。\n",
        "   * **Min–Max** 壓縮到 \\[0,1]；適合需要統一尺度或對「極端值」較不敏感的模型。\n",
        "\n",
        "4. **不平衡標籤的影響與解法**\n",
        "\n",
        "   * **影響**：模型偏向預測多數類別，中、小樣本類錯誤率高。\n",
        "   * **解法**：\n",
        "\n",
        "     * **過採樣**（`resample`／SMOTE）\n",
        "     * **欠採樣**（隨機刪除多數類）\n",
        "     * **調整類別權重**（`class_weight='balanced'`）\n",
        "\n",
        "   ```python\n",
        "   from sklearn.utils import resample\n",
        "   # 以過採樣為例\n",
        "   counts = df_train['quality'].value_counts()\n",
        "   max_n = counts.max()\n",
        "   df_list = []\n",
        "   for q, n in counts.items():\n",
        "       subset = df_train[df_train['quality']==q]\n",
        "       df_list.append(resample(subset, replace=True, n_samples=max_n, random_state=42))\n",
        "   df_balanced = pd.concat(df_list)\n",
        "   print(df_balanced['quality'].value_counts())\n",
        "   ```\n",
        "\n",
        "5. **特徵工程示例**\n",
        "\n",
        "   ```python\n",
        "   df_fe = df_train.copy()\n",
        "   # 1. 酸度比：固定酸度 / 揮發性酸度\n",
        "   df_fe['acidity_ratio'] = df_fe['fixed_acidity'] / df_fe['volatile_acidity']\n",
        "   # 2. 硫氧比：游離SO₂ / 總SO₂\n",
        "   df_fe['sulfur_ratio'] = df_fe['free_sulfur_dioxide'] / df_fe['total_sulfur_dioxide']\n",
        "   # 3. 酒精密度比：酒精含量 / 密度\n",
        "   df_fe['alcohol_density_ratio'] = df_fe['alcohol'] / df_fe['density']\n",
        "\n",
        "   print(df_fe[['acidity_ratio','sulfur_ratio','alcohol_density_ratio']].head())\n",
        "   ```\n",
        "\n",
        "   * 這些新變數往往能揭露「不同化學指標間的交互關係」，有助提升模型表現。\n",
        "\n",
        "──\n"
      ],
      "metadata": {
        "id": "LkzPb3FaOQBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **欄位定義**（依照 Kaggle/UCI 文件）\n",
        "\n",
        "   > 所有單位都以 g/dm³ 計，除非另註。\n",
        "\n",
        "   * `fixed_acidity`：固定酸度（檸檬酸、蘋果酸等除揮發性酸外的總酸）\n",
        "   * `volatile_acidity`：揮發性酸度（主要是醋酸，過高會產生醋味）\n",
        "   * `citric_acid`：檸檬酸（少量有助於風味和新鮮感）\n",
        "   * `residual_sugar`：殘留糖分（發酵後仍存在的糖，過高易甜膩）\n",
        "   * `chlorides`：氯化物（鹽分量，過高會感覺鹹）\n",
        "   * `free_sulfur_dioxide`：游離二氧化硫（抗氧化劑，過量會嗆鼻）\n",
        "   * `total_sulfur_dioxide`：總二氧化硫（游離＋結合型）\n",
        "   * `density`：密度（與糖分、酒精、溫度有關）\n",
        "   * `pH`：酸鹼值（小於3 表示偏酸）\n",
        "   * `sulphates`：硫酸鹽（促進防腐和風味）\n",
        "   * `alcohol`：酒精含量（% v/v）\n",
        "   * `quality`：品質分數（整數，0–10 分，主觀評分）\n",
        "\n",
        "3. **特徵（features）分佈觀察**\n",
        "\n",
        "   * **固定酸度 (fixed\\_acidity)**：大多集中在 6–10；平均約 8.3，略偏右尾。\n",
        "\n",
        "   * **揮發性酸度 (volatile\\_acidity)**：多數落在0.2–0.6；平均約0.53，右偏（少數高醋酸樣本）。\n",
        "\n",
        "   * **檸檬酸 (citric\\_acid)**：大部分在0.0–0.6；平均約0.27，零或極低的比例也不少。\n",
        "\n",
        "   * **殘留糖分 (residual\\_sugar)**：多集中在0.9–2.5，平均約2；明顯右偏（最高可達15以上）。\n",
        "\n",
        "   * **氯化物 (chlorides)**：主要落在0.03–0.10，平均約0.087，分佈窄且左偏。\n",
        "\n",
        "   * **游離二氧化硫 (free\\_sulfur\\_dioxide)**：多在0–30 mg/dm³，平均約15，很長尾（最高上百）。\n",
        "\n",
        "   * **總二氧化硫 (total\\_sulfur\\_dioxide)**：多在50–150 mg/dm³，平均約120，同樣長尾。\n",
        "\n",
        "   * **密度 (density)**：範圍極窄，約0.990–1.004 g/cm³，分佈近常態，平均≈0.996。\n",
        "\n",
        "   * **pH**：集中在3.1–3.6，平均約3.31，分佈略偏左。\n",
        "\n",
        "   * **硫酸鹽 (sulphates)**：主要落在0.4–0.8，平均約0.66，分佈偏左。\n",
        "\n",
        "   * **酒精含量 (alcohol)**：範圍7–14%，平均約10.4%，分佈近常態但略右尾。\n",
        "\n",
        "   > **總結**：多數特徵的分佈都呈現輕微偏態（尤其是殘糖、揮發性酸度、二氧化硫），而像密度、pH、酒精含量則較接近對稱分佈。\n",
        "\n",
        "4. **標籤（quality）分佈**\n",
        "\n",
        "   * 質量分數範圍：3–8 分\n",
        "\n",
        "   * **5 分與 6 分** 最常見，合計佔全體樣本約70%\n",
        "\n",
        "   * 3、4、7、8 分樣本相對稀少，其中 8 分極少（約0.3%）\n",
        "\n",
        "   > **小結**：資料標籤明顯偏向中間分數，屬於高度不平衡的多分類問題。\n"
      ],
      "metadata": {
        "id": "FGd8DOJ9HGvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **資料分析工作流程必備環節（不考慮準確度）**\n",
        "\n",
        "   1. **定義問題**：釐清業務或研究目標，決定要做分類、迴歸或其他分析。\n",
        "   2. **資料蒐集**：取得原始資料（CSV、資料庫、API…）。\n",
        "   3. **資料檢視（Exploration）**：快速檢查欄位型別、缺失值、重複值與大致分佈。\n",
        "   4. **資料清理**：處理缺失值、重複值、異常值，統一欄位名稱、資料格式。\n",
        "   5. **特徵轉換**：必要時做類別編碼、數值標準化或拆／合新特徵。\n",
        "   6. **資料切分**：依需求切成訓練集、測試集（或驗證集）。\n",
        "   7. **Baseline 建立**：選個簡單模型／基準模型跑一次，檢查 pipeline 無誤。\n",
        "   8. **模型訓練與預測**：用訓練集訓練、測試集預測。\n",
        "   9. **評估與報告**：算指標、畫圖、撰寫結論。"
      ],
      "metadata": {
        "id": "bVnPkvA1IUBY"
      }
    }
  ]
}